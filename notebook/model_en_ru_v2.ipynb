{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model-en-ru_v2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQ-WutnPbf2O",
        "outputId": "a2bb92d0-2da9-4150-f68c-3a177c513812"
      },
      "source": [
        "\r\n",
        "# Install TensorFlow and also our package via PyPI\r\n",
        "!pip install tensorflow-gpu\r\n",
        "!pip install headliner"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/aa/ae64be5acaac9055329289e6bfd54c1efa28bfe792f9021cea495fe2b89d/tensorflow_gpu-2.4.0-cp36-cp36m-manylinux2010_x86_64.whl (394.7MB)\n",
            "\u001b[K     |████████████████████████████████| 394.7MB 44kB/s \n",
            "\u001b[?25hRequirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.36.2)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.4.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.6.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.7.4.3)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.3.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.4.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.10.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.3.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.32.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.1)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.10.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.19.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (3.3.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (51.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (1.7.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (1.17.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (0.4.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow-gpu) (3.3.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu) (4.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow-gpu) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow-gpu) (3.4.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow-gpu) (3.1.0)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-2.4.0\n",
            "Collecting headliner\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/e4/386e9f58b8464261d4e220abaebe66da2426d55b6ea4186ec2cb828195ef/headliner-1.0.2-py3-none-any.whl (65kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 9.1MB/s \n",
            "\u001b[?25hCollecting transformers>=2.2.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/0c/7d5950fcd80b029be0a8891727ba21e0cd27692c407c51261c3c921f6da3/transformers-4.1.1-py3-none-any.whl (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 14.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from headliner) (0.22.2.post1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from headliner) (3.13)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from headliner) (2.2.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from headliner) (3.2.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.2.2->headliner) (4.41.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers>=2.2.2->headliner) (0.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers>=2.2.2->headliner) (1.19.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.2.2->headliner) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 53.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers>=2.2.2->headliner) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers>=2.2.2->headliner) (2.23.0)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 54.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers>=2.2.2->headliner) (20.8)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->headliner) (1.0.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->headliner) (1.4.1)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->headliner) (0.4.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->headliner) (1.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->headliner) (3.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->headliner) (7.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->headliner) (1.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->headliner) (1.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->headliner) (1.1.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->headliner) (2.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->headliner) (51.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->headliner) (0.8.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->headliner) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=2.2.2->headliner) (7.1.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.2.2->headliner) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.2.2->headliner) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.2.2->headliner) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.2.2->headliner) (2.10)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers>=2.2.2->headliner) (2.4.7)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->headliner) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->headliner) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->headliner) (3.4.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=50ec42c3391e24f9e85261441cfe39e5026c95cf19ec16177f9a204df08dc3be\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers, headliner\n",
            "Successfully installed headliner-1.0.2 sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1M21XF8buze",
        "outputId": "f13097a3-e9f6-4c8d-9f99-4453b768d42b"
      },
      "source": [
        "!wget http://www.manythings.org/anki/rus-eng.zip\r\n",
        "!unzip rus-eng.zip\r\n",
        "!head rus.txt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-26 21:20:06--  http://www.manythings.org/anki/rus-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 104.24.108.196, 172.67.173.198, 104.24.109.196, ...\n",
            "Connecting to www.manythings.org (www.manythings.org)|104.24.108.196|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13811083 (13M) [application/zip]\n",
            "Saving to: ‘rus-eng.zip’\n",
            "\n",
            "rus-eng.zip         100%[===================>]  13.17M  27.2MB/s    in 0.5s    \n",
            "\n",
            "2020-12-26 21:20:07 (27.2 MB/s) - ‘rus-eng.zip’ saved [13811083/13811083]\n",
            "\n",
            "Archive:  rus-eng.zip\n",
            "  inflating: rus.txt                 \n",
            "  inflating: _about.txt              \n",
            "Go.\tМарш!\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #1159202 (shanghainese)\n",
            "Go.\tИди.\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #5898247 (marafon)\n",
            "Go.\tИдите.\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #5898250 (marafon)\n",
            "Hi.\tЗдравствуйте.\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #402127 (odexed)\n",
            "Hi.\tПривет!\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #466968 (katjka)\n",
            "Hi.\tХай.\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #467233 (timsa)\n",
            "Hi.\tЗдрасте.\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #3803577 (marafon)\n",
            "Hi.\tЗдоро́во!\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #3854188 (marafon)\n",
            "Run!\tБеги!\tCC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #1569978 (Biga)\n",
            "Run!\tБегите!\tCC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #2770234 (marafon)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9k2MBjnKcVTH",
        "outputId": "e85bc602-7cdc-4ee1-f6f5-e35cf4cfa452"
      },
      "source": [
        "# Create the dataset but only take a subset for faster training\r\n",
        "import io\r\n",
        "\r\n",
        "def create_dataset(path, num_examples):\r\n",
        "    lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\r\n",
        "    word_pairs = [[w for w in l.split('\\t')]  for l in lines[:num_examples]]\r\n",
        "    return zip(*word_pairs)\r\n",
        "\r\n",
        "eng, rus, meta = create_dataset('rus.txt', 30000)\r\n",
        "data = list(zip(eng, rus))\r\n",
        "data[:5]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Go.', 'Марш!'),\n",
              " ('Go.', 'Иди.'),\n",
              " ('Go.', 'Идите.'),\n",
              " ('Hi.', 'Здравствуйте.'),\n",
              " ('Hi.', 'Привет!')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2ZeykdYch6H"
      },
      "source": [
        "# Split the dataset into train and test\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "train, test = train_test_split(data, test_size=100)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zE-QrjV2dHv_",
        "outputId": "851bf438-6112-4af2-aa69-dbb6aa9d6ab8"
      },
      "source": [
        "len(train)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29900"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dm4weoNRclT8",
        "outputId": "e866c920-860a-41ee-af38-0c1439cb2f13"
      },
      "source": [
        "# Define the model and train it\r\n",
        "import tensorflow as tf\r\n",
        "from headliner.trainer import Trainer\r\n",
        "from headliner.model.attention_summarizer import AttentionSummarizer\r\n",
        "\r\n",
        "summarizer = AttentionSummarizer(lstm_size=256, embedding_size=64, max_prediction_len=10)\r\n",
        "trainer = Trainer(batch_size=32, \r\n",
        "                  steps_per_epoch=500, \r\n",
        "                  steps_to_log=50, \r\n",
        "                  max_vocab_size_encoder=30000,\r\n",
        "                  max_vocab_size_decoder=30000,\r\n",
        "                  max_output_len=10,\r\n",
        "                  model_save_path='/tmp/summarizer')\r\n",
        "trainer.train(summarizer, train, num_epochs=10, val_data=test)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training a bare model, preprocessing data to init model...\n",
            "fitting tokenizers...\n",
            "vocab encoder: 3582, vocab decoder: 9829\n",
            "epoch 0, batch 50, logs: {'loss': 3.4555767822265624}\n",
            "epoch 0, batch 100, logs: {'loss': 3.16320556640625}\n",
            "epoch 0, batch 150, logs: {'loss': 3.049910481770833}\n",
            "epoch 0, batch 200, logs: {'loss': 2.982446594238281}\n",
            "epoch 0, batch 250, logs: {'loss': 2.927796630859375}\n",
            "epoch 0, batch 300, logs: {'loss': 2.8833502197265624}\n",
            "epoch 0, batch 350, logs: {'loss': 2.8410792759486605}\n",
            "epoch 0, batch 400, logs: {'loss': 2.7926870727539064}\n",
            "epoch 0, batch 450, logs: {'loss': 2.752205132378472}\n",
            "epoch 0, batch 500, logs: {'loss': 2.70997802734375}\n",
            "\n",
            "(input) <start> she is kind . <end> \n",
            "(target) <start> она добрая . <end> \n",
            "(prediction) я не не . <end>\n",
            "\n",
            "\n",
            "(input) <start> it may break . <end> \n",
            "(target) <start> он может сломаться . <end> \n",
            "(prediction) я не не не . <end>\n",
            "\n",
            "\n",
            "(input) <start> we need a goal . <end> \n",
            "(target) <start> нам нужна цель . <end> \n",
            "(prediction) я не не не не . <end>\n",
            "\n",
            "\n",
            "(input) <start> tom will eat . <end> \n",
            "(target) <start> том поест . <end> \n",
            "(prediction) я не не не . <end>\n",
            "\n",
            "\n",
            "(input) <start> that's lame . <end> \n",
            "(target) <start> неубедительно . <end> \n",
            "(prediction) . <end>\n",
            "\n",
            "loss_val improved from None to 2.3548424243927, saving summarizer to /tmp/summarizer\n",
            "epoch 1, batch 550, logs: {'loss': 2.2963092041015627, 'loss_val': 2.3548424243927}\n",
            "epoch 1, batch 600, logs: {'loss': 2.2863861083984376, 'loss_val': 2.3548424243927}\n",
            "epoch 1, batch 650, logs: {'loss': 2.2681241861979164, 'loss_val': 2.3548424243927}\n",
            "epoch 1, batch 700, logs: {'loss': 2.2591618347167968, 'loss_val': 2.3548424243927}\n",
            "epoch 1, batch 750, logs: {'loss': 2.24690771484375, 'loss_val': 2.3548424243927}\n",
            "epoch 1, batch 800, logs: {'loss': 2.232474772135417, 'loss_val': 2.3548424243927}\n",
            "epoch 1, batch 850, logs: {'loss': 2.2194524274553573, 'loss_val': 2.3548424243927}\n",
            "epoch 1, batch 900, logs: {'loss': 2.205079345703125, 'loss_val': 2.3548424243927}\n",
            "finished iterating over dataset, total batches: 934\n",
            "epoch 1, batch 950, logs: {'loss': 2.187713080512153, 'loss_val': 2.3548424243927}\n",
            "epoch 1, batch 1000, logs: {'loss': 2.163134033203125, 'loss_val': 2.3548424243927}\n",
            "\n",
            "(input) <start> she is kind . <end> \n",
            "(target) <start> она добрая . <end> \n",
            "(prediction) это орать . <end>\n",
            "\n",
            "\n",
            "(input) <start> it may break . <end> \n",
            "(target) <start> он может сломаться . <end> \n",
            "(prediction) это его . <end>\n",
            "\n",
            "\n",
            "(input) <start> we need a goal . <end> \n",
            "(target) <start> нам нужна цель . <end> \n",
            "(prediction) это это его . <end>\n",
            "\n",
            "\n",
            "(input) <start> tom will eat . <end> \n",
            "(target) <start> том поест . <end> \n",
            "(prediction) я был есть . <end>\n",
            "\n",
            "\n",
            "(input) <start> that's lame . <end> \n",
            "(target) <start> неубедительно . <end> \n",
            "(prediction) это на это . <end>\n",
            "\n",
            "loss_val improved from 2.3548424243927 to 2.0186328887939453, saving summarizer to /tmp/summarizer\n",
            "epoch 2, batch 1050, logs: {'loss': 1.9243687438964843, 'loss_val': 2.0186328887939453}\n",
            "epoch 2, batch 1100, logs: {'loss': 1.9192314147949219, 'loss_val': 2.0186328887939453}\n",
            "epoch 2, batch 1150, logs: {'loss': 1.905951944986979, 'loss_val': 2.0186328887939453}\n",
            "epoch 2, batch 1200, logs: {'loss': 1.88661376953125, 'loss_val': 2.0186328887939453}\n",
            "epoch 2, batch 1250, logs: {'loss': 1.8811351318359375, 'loss_val': 2.0186328887939453}\n",
            "epoch 2, batch 1300, logs: {'loss': 1.8689471435546876, 'loss_val': 2.0186328887939453}\n",
            "epoch 2, batch 1350, logs: {'loss': 1.8600667898995535, 'loss_val': 2.0186328887939453}\n",
            "epoch 2, batch 1400, logs: {'loss': 1.8469554138183595, 'loss_val': 2.0186328887939453}\n",
            "epoch 2, batch 1450, logs: {'loss': 1.8407866753472222, 'loss_val': 2.0186328887939453}\n",
            "epoch 2, batch 1500, logs: {'loss': 1.833880859375, 'loss_val': 2.0186328887939453}\n",
            "\n",
            "(input) <start> she is kind . <end> \n",
            "(target) <start> она добрая . <end> \n",
            "(prediction) это - машине . <end>\n",
            "\n",
            "\n",
            "(input) <start> it may break . <end> \n",
            "(target) <start> он может сломаться . <end> \n",
            "(prediction) это не в ума . <end>\n",
            "\n",
            "\n",
            "(input) <start> we need a goal . <end> \n",
            "(target) <start> нам нужна цель . <end> \n",
            "(prediction) он не были в ума . <end>\n",
            "\n",
            "\n",
            "(input) <start> tom will eat . <end> \n",
            "(target) <start> том поест . <end> \n",
            "(prediction) том был в ума . <end>\n",
            "\n",
            "\n",
            "(input) <start> that's lame . <end> \n",
            "(target) <start> неубедительно . <end> \n",
            "(prediction) это в ума . <end>\n",
            "\n",
            "loss_val improved from 2.0186328887939453 to 1.8175281286239624, saving summarizer to /tmp/summarizer\n",
            "epoch 3, batch 1550, logs: {'loss': 1.7198321533203125, 'loss_val': 1.8175281286239624}\n",
            "epoch 3, batch 1600, logs: {'loss': 1.7155543518066407, 'loss_val': 1.8175281286239624}\n",
            "epoch 3, batch 1650, logs: {'loss': 1.7097719319661457, 'loss_val': 1.8175281286239624}\n",
            "epoch 3, batch 1700, logs: {'loss': 1.7065397644042968, 'loss_val': 1.8175281286239624}\n",
            "epoch 3, batch 1750, logs: {'loss': 1.696646240234375, 'loss_val': 1.8175281286239624}\n",
            "epoch 3, batch 1800, logs: {'loss': 1.6918492635091147, 'loss_val': 1.8175281286239624}\n",
            "epoch 3, batch 1850, logs: {'loss': 1.6836068289620536, 'loss_val': 1.8175281286239624}\n",
            "finished iterating over dataset, total batches: 1868\n",
            "epoch 3, batch 1900, logs: {'loss': 1.6695556640625, 'loss_val': 1.8175281286239624}\n",
            "epoch 3, batch 1950, logs: {'loss': 1.6533060709635417, 'loss_val': 1.8175281286239624}\n",
            "epoch 3, batch 2000, logs: {'loss': 1.63712255859375, 'loss_val': 1.8175281286239624}\n",
            "\n",
            "(input) <start> she is kind . <end> \n",
            "(target) <start> она добрая . <end> \n",
            "(prediction) это - автобусе . <end>\n",
            "\n",
            "\n",
            "(input) <start> it may break . <end> \n",
            "(target) <start> он может сломаться . <end> \n",
            "(prediction) это не будем . <end>\n",
            "\n",
            "\n",
            "(input) <start> we need a goal . <end> \n",
            "(target) <start> нам нужна цель . <end> \n",
            "(prediction) мы не лжёт . <end>\n",
            "\n",
            "\n",
            "(input) <start> tom will eat . <end> \n",
            "(target) <start> том поест . <end> \n",
            "(prediction) том был в замешательстве . <end>\n",
            "\n",
            "\n",
            "(input) <start> that's lame . <end> \n",
            "(target) <start> неубедительно . <end> \n",
            "(prediction) это в замешательстве . <end>\n",
            "\n",
            "loss_val improved from 1.8175281286239624 to 1.7082682847976685, saving summarizer to /tmp/summarizer\n",
            "epoch 4, batch 2050, logs: {'loss': 1.5017414855957032, 'loss_val': 1.7082682847976685}\n",
            "epoch 4, batch 2100, logs: {'loss': 1.494478759765625, 'loss_val': 1.7082682847976685}\n",
            "epoch 4, batch 2150, logs: {'loss': 1.4912433878580729, 'loss_val': 1.7082682847976685}\n",
            "epoch 4, batch 2200, logs: {'loss': 1.4903721618652344, 'loss_val': 1.7082682847976685}\n",
            "epoch 4, batch 2250, logs: {'loss': 1.480962890625, 'loss_val': 1.7082682847976685}\n",
            "epoch 4, batch 2300, logs: {'loss': 1.4717044067382812, 'loss_val': 1.7082682847976685}\n",
            "epoch 4, batch 2350, logs: {'loss': 1.4666278948102678, 'loss_val': 1.7082682847976685}\n",
            "epoch 4, batch 2400, logs: {'loss': 1.460301513671875, 'loss_val': 1.7082682847976685}\n",
            "epoch 4, batch 2450, logs: {'loss': 1.4535148111979166, 'loss_val': 1.7082682847976685}\n",
            "epoch 4, batch 2500, logs: {'loss': 1.451873046875, 'loss_val': 1.7082682847976685}\n",
            "\n",
            "(input) <start> she is kind . <end> \n",
            "(target) <start> она добрая . <end> \n",
            "(prediction) она сгорит . <end>\n",
            "\n",
            "\n",
            "(input) <start> it may break . <end> \n",
            "(target) <start> он может сломаться . <end> \n",
            "(prediction) это может помочь . <end>\n",
            "\n",
            "\n",
            "(input) <start> we need a goal . <end> \n",
            "(target) <start> нам нужна цель . <end> \n",
            "(prediction) мы может такси . <end>\n",
            "\n",
            "\n",
            "(input) <start> tom will eat . <end> \n",
            "(target) <start> том поест . <end> \n",
            "(prediction) том был взволнован . <end>\n",
            "\n",
            "\n",
            "(input) <start> that's lame . <end> \n",
            "(target) <start> неубедительно . <end> \n",
            "(prediction) это ужасно . <end>\n",
            "\n",
            "loss_val improved from 1.7082682847976685 to 1.5408259630203247, saving summarizer to /tmp/summarizer\n",
            "epoch 5, batch 2550, logs: {'loss': 1.4133389282226563, 'loss_val': 1.5408259630203247}\n",
            "epoch 5, batch 2600, logs: {'loss': 1.403831024169922, 'loss_val': 1.5408259630203247}\n",
            "epoch 5, batch 2650, logs: {'loss': 1.3911834716796876, 'loss_val': 1.5408259630203247}\n",
            "epoch 5, batch 2700, logs: {'loss': 1.383864288330078, 'loss_val': 1.5408259630203247}\n",
            "epoch 5, batch 2750, logs: {'loss': 1.37931298828125, 'loss_val': 1.5408259630203247}\n",
            "epoch 5, batch 2800, logs: {'loss': 1.3752296956380208, 'loss_val': 1.5408259630203247}\n",
            "finished iterating over dataset, total batches: 2802\n",
            "epoch 5, batch 2850, logs: {'loss': 1.350355224609375, 'loss_val': 1.5408259630203247}\n",
            "epoch 5, batch 2900, logs: {'loss': 1.3288023376464844, 'loss_val': 1.5408259630203247}\n",
            "epoch 5, batch 2950, logs: {'loss': 1.31396484375, 'loss_val': 1.5408259630203247}\n",
            "epoch 5, batch 3000, logs: {'loss': 1.2987335205078125, 'loss_val': 1.5408259630203247}\n",
            "\n",
            "(input) <start> she is kind . <end> \n",
            "(target) <start> она добрая . <end> \n",
            "(prediction) она - свидание . <end>\n",
            "\n",
            "\n",
            "(input) <start> it may break . <end> \n",
            "(target) <start> он может сломаться . <end> \n",
            "(prediction) это может попробовать . <end>\n",
            "\n",
            "\n",
            "(input) <start> we need a goal . <end> \n",
            "(target) <start> нам нужна цель . <end> \n",
            "(prediction) мы может пойти . <end>\n",
            "\n",
            "\n",
            "(input) <start> tom will eat . <end> \n",
            "(target) <start> том поест . <end> \n",
            "(prediction) том был в ярости . <end>\n",
            "\n",
            "\n",
            "(input) <start> that's lame . <end> \n",
            "(target) <start> неубедительно . <end> \n",
            "(prediction) это ваше . <end>\n",
            "\n",
            "loss_val improved from 1.5408259630203247 to 1.4709553718566895, saving summarizer to /tmp/summarizer\n",
            "epoch 6, batch 3050, logs: {'loss': 1.195807876586914, 'loss_val': 1.4709553718566895}\n",
            "epoch 6, batch 3100, logs: {'loss': 1.1810492706298827, 'loss_val': 1.4709553718566895}\n",
            "epoch 6, batch 3150, logs: {'loss': 1.1767427571614584, 'loss_val': 1.4709553718566895}\n",
            "epoch 6, batch 3200, logs: {'loss': 1.1765182495117188, 'loss_val': 1.4709553718566895}\n",
            "epoch 6, batch 3250, logs: {'loss': 1.1768350830078125, 'loss_val': 1.4709553718566895}\n",
            "epoch 6, batch 3300, logs: {'loss': 1.1727974446614584, 'loss_val': 1.4709553718566895}\n",
            "epoch 6, batch 3350, logs: {'loss': 1.1712144252232144, 'loss_val': 1.4709553718566895}\n",
            "epoch 6, batch 3400, logs: {'loss': 1.1696597290039064, 'loss_val': 1.4709553718566895}\n",
            "epoch 6, batch 3450, logs: {'loss': 1.1671259223090278, 'loss_val': 1.4709553718566895}\n",
            "epoch 6, batch 3500, logs: {'loss': 1.1658297119140626, 'loss_val': 1.4709553718566895}\n",
            "\n",
            "(input) <start> she is kind . <end> \n",
            "(target) <start> она добрая . <end> \n",
            "(prediction) она - брюзга . <end>\n",
            "\n",
            "\n",
            "(input) <start> it may break . <end> \n",
            "(target) <start> он может сломаться . <end> \n",
            "(prediction) это может поговорить . <end>\n",
            "\n",
            "\n",
            "(input) <start> we need a goal . <end> \n",
            "(target) <start> нам нужна цель . <end> \n",
            "(prediction) нам нужно отдохнуть . <end>\n",
            "\n",
            "\n",
            "(input) <start> tom will eat . <end> \n",
            "(target) <start> том поест . <end> \n",
            "(prediction) том чувствовал себя в обморок . <end>\n",
            "\n",
            "\n",
            "(input) <start> that's lame . <end> \n",
            "(target) <start> неубедительно . <end> \n",
            "(prediction) это странно . <end>\n",
            "\n",
            "loss_val improved from 1.4709553718566895 to 1.3757127523422241, saving summarizer to /tmp/summarizer\n",
            "epoch 7, batch 3550, logs: {'loss': 1.141778793334961, 'loss_val': 1.3757127523422241}\n",
            "epoch 7, batch 3600, logs: {'loss': 1.1347815704345703, 'loss_val': 1.3757127523422241}\n",
            "epoch 7, batch 3650, logs: {'loss': 1.1403256225585938, 'loss_val': 1.3757127523422241}\n",
            "epoch 7, batch 3700, logs: {'loss': 1.1349504089355469, 'loss_val': 1.3757127523422241}\n",
            "finished iterating over dataset, total batches: 3736\n",
            "epoch 7, batch 3750, logs: {'loss': 1.120633544921875, 'loss_val': 1.3757127523422241}\n",
            "epoch 7, batch 3800, logs: {'loss': 1.0896103922526041, 'loss_val': 1.3757127523422241}\n",
            "epoch 7, batch 3850, logs: {'loss': 1.0700639997209822, 'loss_val': 1.3757127523422241}\n",
            "epoch 7, batch 3900, logs: {'loss': 1.0524021911621093, 'loss_val': 1.3757127523422241}\n",
            "epoch 7, batch 3950, logs: {'loss': 1.039492933485243, 'loss_val': 1.3757127523422241}\n",
            "epoch 7, batch 4000, logs: {'loss': 1.0309132080078125, 'loss_val': 1.3757127523422241}\n",
            "\n",
            "(input) <start> she is kind . <end> \n",
            "(target) <start> она добрая . <end> \n",
            "(prediction) она - брюзга . <end>\n",
            "\n",
            "\n",
            "(input) <start> it may break . <end> \n",
            "(target) <start> он может сломаться . <end> \n",
            "(prediction) это может помощь . <end>\n",
            "\n",
            "\n",
            "(input) <start> we need a goal . <end> \n",
            "(target) <start> нам нужна цель . <end> \n",
            "(prediction) нам нужен план . <end>\n",
            "\n",
            "\n",
            "(input) <start> tom will eat . <end> \n",
            "(target) <start> том поест . <end> \n",
            "(prediction) том работал . <end>\n",
            "\n",
            "\n",
            "(input) <start> that's lame . <end> \n",
            "(target) <start> неубедительно . <end> \n",
            "(prediction) это странно . <end>\n",
            "\n",
            "loss_val improved from 1.3757127523422241 to 1.2927879095077515, saving summarizer to /tmp/summarizer\n",
            "epoch 8, batch 4050, logs: {'loss': 0.9722337341308593, 'loss_val': 1.2927879095077515}\n",
            "epoch 8, batch 4100, logs: {'loss': 0.9664173889160156, 'loss_val': 1.2927879095077515}\n",
            "epoch 8, batch 4150, logs: {'loss': 0.9670440673828125, 'loss_val': 1.2927879095077515}\n",
            "epoch 8, batch 4200, logs: {'loss': 0.9633370208740234, 'loss_val': 1.2927879095077515}\n",
            "epoch 8, batch 4250, logs: {'loss': 0.956275390625, 'loss_val': 1.2927879095077515}\n",
            "epoch 8, batch 4300, logs: {'loss': 0.9549465942382812, 'loss_val': 1.2927879095077515}\n",
            "epoch 8, batch 4350, logs: {'loss': 0.953883318219866, 'loss_val': 1.2927879095077515}\n",
            "epoch 8, batch 4400, logs: {'loss': 0.9542369842529297, 'loss_val': 1.2927879095077515}\n",
            "epoch 8, batch 4450, logs: {'loss': 0.9532708062065972, 'loss_val': 1.2927879095077515}\n",
            "epoch 8, batch 4500, logs: {'loss': 0.95285595703125, 'loss_val': 1.2927879095077515}\n",
            "\n",
            "(input) <start> she is kind . <end> \n",
            "(target) <start> она добрая . <end> \n",
            "(prediction) она - адвокат . <end>\n",
            "\n",
            "\n",
            "(input) <start> it may break . <end> \n",
            "(target) <start> он может сломаться . <end> \n",
            "(prediction) это может уехать . <end>\n",
            "\n",
            "\n",
            "(input) <start> we need a goal . <end> \n",
            "(target) <start> нам нужна цель . <end> \n",
            "(prediction) нам нужно сесть . <end>\n",
            "\n",
            "\n",
            "(input) <start> tom will eat . <end> \n",
            "(target) <start> том поест . <end> \n",
            "(prediction) том чувствовал себя виноватым . <end>\n",
            "\n",
            "\n",
            "(input) <start> that's lame . <end> \n",
            "(target) <start> неубедительно . <end> \n",
            "(prediction) это семь . <end>\n",
            "\n",
            "loss_val improved from 1.2927879095077515 to 1.256422519683838, saving summarizer to /tmp/summarizer\n",
            "epoch 9, batch 4550, logs: {'loss': 0.9145030212402344, 'loss_val': 1.256422519683838}\n",
            "epoch 9, batch 4600, logs: {'loss': 0.9215859985351562, 'loss_val': 1.256422519683838}\n",
            "epoch 9, batch 4650, logs: {'loss': 0.9253912353515625, 'loss_val': 1.256422519683838}\n",
            "finished iterating over dataset, total batches: 4670\n",
            "epoch 9, batch 4700, logs: {'loss': 0.8992867279052734, 'loss_val': 1.256422519683838}\n",
            "epoch 9, batch 4750, logs: {'loss': 0.8731041870117188, 'loss_val': 1.256422519683838}\n",
            "epoch 9, batch 4800, logs: {'loss': 0.8533093770345052, 'loss_val': 1.256422519683838}\n",
            "epoch 9, batch 4850, logs: {'loss': 0.842646745954241, 'loss_val': 1.256422519683838}\n",
            "epoch 9, batch 4900, logs: {'loss': 0.8319903564453125, 'loss_val': 1.256422519683838}\n",
            "epoch 9, batch 4950, logs: {'loss': 0.8255532497829862, 'loss_val': 1.256422519683838}\n",
            "epoch 9, batch 5000, logs: {'loss': 0.8211825561523437, 'loss_val': 1.256422519683838}\n",
            "\n",
            "(input) <start> she is kind . <end> \n",
            "(target) <start> она добрая . <end> \n",
            "(prediction) она - венгерка . <end>\n",
            "\n",
            "\n",
            "(input) <start> it may break . <end> \n",
            "(target) <start> он может сломаться . <end> \n",
            "(prediction) это может поговорить . <end>\n",
            "\n",
            "\n",
            "(input) <start> we need a goal . <end> \n",
            "(target) <start> нам нужна цель . <end> \n",
            "(prediction) нам нужен вино . <end>\n",
            "\n",
            "\n",
            "(input) <start> tom will eat . <end> \n",
            "(target) <start> том поест . <end> \n",
            "(prediction) том чувствовал себя счастливой . <end>\n",
            "\n",
            "\n",
            "(input) <start> that's lame . <end> \n",
            "(target) <start> неубедительно . <end> \n",
            "(prediction) это новое . <end>\n",
            "\n",
            "loss_val improved from 1.256422519683838 to 1.2064218521118164, saving summarizer to /tmp/summarizer\n",
            "finished iterating over dataset, total batches: 5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_ac9psRWco3k",
        "outputId": "ca9af1ba-909a-41b0-ab17-cfc6d88d00c1"
      },
      "source": [
        "summarizer.predict('Do you have a plan?')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'у вас есть план ? <end>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRANy8PkhEMw"
      },
      "source": [
        "Построим какую-нибудь картинку"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4pPUdwHjoZ-",
        "outputId": "c99f49bd-53ad-44b8-a613-6e1c4db53f06"
      },
      "source": [
        "!zip -r model-en-ru_v2.zip  /tmp/summarizer/"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: tmp/summarizer/ (stored 0%)\n",
            "  adding: tmp/summarizer/decoder.index (deflated 65%)\n",
            "  adding: tmp/summarizer/summarizer.pkl (deflated 64%)\n",
            "  adding: tmp/summarizer/encoder.index (deflated 58%)\n",
            "  adding: tmp/summarizer/decoder.data-00000-of-00001 (deflated 8%)\n",
            "  adding: tmp/summarizer/encoder.data-00000-of-00001 (deflated 7%)\n",
            "  adding: tmp/summarizer/checkpoint (deflated 38%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "TAa6jtWklHII",
        "outputId": "42c1c66d-0b55-4e76-fed0-5a6b32cc30a9"
      },
      "source": [
        "from google.colab import files\r\n",
        "files.download(\"./model-en-ru_v2.zip\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_cb0f6819-2697-4e82-acc1-f48637594fca\", \"model-en-ru_v2.zip\", 47154523)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uE2A26XVl5zv",
        "outputId": "54787aff-7e0d-47ed-d8d5-1b7c150216a9"
      },
      "source": [
        ""
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    }
  ]
}